1/3會議記錄:
我們本來想用LLaMA做微調，但由於硬體資源的限制，使我們決定不用LLaMA，並考慮其他更輕量化且資源友好的替代方案。
(EX:串接Gemini的api，讓gemini回答使用者的問題，最容易實現。)

1.我們電腦可以跑LLaMA 3.2 0.5B、1B ，但不能微調，而且它們很會幻想。
GPU內存需要至少12G。並且自己從頭訓練5億個參數太多了，不可行。

2.LLaMA 3.2 7B啟動就需要4G的GPU，所以我們的設備規格不OK。


RAG可用Groq的LLM，結合檢索到的文本進行生成。

CAG（Context-Augmented Generation）可以使用 LLM，結合檢索到的文本進行生成，以提供更準確和上下文相關的回答。
CAG比RAG優秀，但是CAG的論文前兩三天才出來，並且但網路上還沒有看到有人實作分享。

可以讓三個人分別操作Azure、GCP、AWS，看看哪個雲端平台最好用
Oracle Cloud也可操作看看，但Oracle Cloud只能免費用30天 

結論:泰瑞跟陳龍負責研究CAG
     耀立、家瑋、文遠負責找LLM的文本(txt檔)
